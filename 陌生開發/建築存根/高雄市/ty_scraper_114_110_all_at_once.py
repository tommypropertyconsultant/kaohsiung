#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import time
import os
import logging
import pandas as pd
import random
import re
import threading
import csv
from datetime import datetime

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException

# è¨­å®š Log
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ==========================================
# âœ… è¨­å®šå­˜æª”è·¯å¾‘
BASE_PATH = r'/Users/wangliwen/Desktop/ JLL/é™Œç”Ÿé–‹ç™¼/å»ºç¯‰å­˜æ ¹/æ¡ƒåœ’å¸‚'

# ğŸ¯ è¨­å®šå¹´ä»½çµ„ (ä¸€æ¬¡å…¨é–‹ï¼)
# å°‡æ‰€æœ‰å¹´ä»½æ”¾åœ¨åŒä¸€å€‹åˆ—è¡¨ä¸­ï¼Œç¨‹å¼æœƒåŒæ™‚å•Ÿå‹• 5 å€‹è¦–çª—
YEAR_BATCHES = [
    ["114", "113", "112", "111", "110"]
]

# ğŸ¯ è¨­å®šç¯„åœ
START_NUM = 0
END_NUM = 3000

# ğŸ›‘ åœæè¨­å®š (ç¶­æŒåš´æ ¼æ¨™æº–)
MAX_SAME_NUM_RETRIES = 3       # å–®è™Ÿé‡è©¦ 3 æ¬¡
MAX_CONSECUTIVE_YEAR_FAILS = 5 # é€£çºŒ 5 è™Ÿç©ºå°±åœ
# ==========================================

class TyScraperStrict114:
    def __init__(self, target_year, start_num, end_num, output_filename):
        self.url = "https://building.tycg.gov.tw/bupic/preLoginFormAction.do"
        self.target_year = target_year
        self.start_num = start_num
        self.end_num = end_num
        self.output_filename = output_filename
        self.csv_filename = output_filename.replace(".xlsx", ".csv")
        self.driver = None
        self.results = []
        
        self.target_folder = os.path.join(BASE_PATH, self.target_year)
        if not os.path.exists(self.target_folder):
            try:
                os.makedirs(self.target_folder)
                logger.info(f"ğŸ“ [{self.target_year}] è³‡æ–™å¤¾æº–å‚™å°±ç·’")
            except: pass

        self.init_csv()

    def init_csv(self):
        csv_path = os.path.join(self.target_folder, self.csv_filename)
        if not os.path.exists(csv_path):
            columns = [
                "æœå°‹ç·¨è™Ÿ", "åŸ·ç…§è™Ÿç¢¼", "èµ·é€ äºº", "è¡Œæ”¿å€", "å»ºç¯‰åœ°é»", 
                "ä½¿ç”¨åˆ†å€", "å±¤æ£Ÿæˆ¶æ•¸", "åŸºåœ°é¢ç©(åˆè¨ˆ)", "å»ºç¯‰é¢ç©(å…¶ä»–)", 
                "æ³•å®šç©ºåœ°é¢ç©", "ç¸½æ¨“åœ°æ¿é¢ç©", "ç™¼ç…§æ—¥æœŸ", "ä½¿ç”¨é¡çµ„"
            ]
            try:
                with open(csv_path, mode='w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=columns)
                    writer.writeheader()
            except Exception as e:
                logger.error(f"âš ï¸ CSV åˆå§‹åŒ–å¤±æ•—: {e}")

    def save_row_to_csv(self, record):
        csv_path = os.path.join(self.target_folder, self.csv_filename)
        try:
            with open(csv_path, mode='a', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=record.keys())
                writer.writerow(record)
        except Exception as e:
            logger.error(f"âš ï¸ å–®ç­†å¯«å…¥å¤±æ•—: {e}")

    def init_driver(self):
        options = Options()
        options.add_argument('--headless=new') 
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')
        options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    def close_driver(self):
        if self.driver:
            try: self.driver.quit()
            except: pass
            self.driver = None

    def solve_captcha_direct(self):
        try:
            return self.driver.find_element(By.ID, "checkCode").text.strip() or \
                   self.driver.execute_script("return document.getElementById('checkCode').innerText")
        except: return ""

    def get_full_text_safe(self):
        try: return self.driver.execute_script("var text = document.body.innerText; return text;")
        except: return ""

    def extract_value_from_text(self, text_source, start_keywords, end_keywords=None):
        for key in start_keywords:
            if key in text_source:
                try:
                    temp = text_source.split(key, 1)[1].strip()
                    if temp.startswith(":") or temp.startswith("ï¼š"): temp = temp[1:].strip()
                    if end_keywords:
                        for end_key in end_keywords:
                            if end_key in temp:
                                temp = temp.split(end_key, 1)[0].strip()
                                break
                    lines = temp.split('\n')
                    if lines: return lines[0].strip()
                except: continue
        return ""

    def extract_usage_between_keywords(self, full_text):
        start_key = "ä½¿ç”¨é¡çµ„"
        end_key = "å‚™è¨»" 
        backup_end_keys = ["æ³¨æ„äº‹é …", "èµ·é€ äºº", "è¨­è¨ˆäºº", "èªªæ˜", "ç™¼ç…§æ—¥æœŸ"]
        if start_key not in full_text: return ""
        try:
            content_after_start = full_text.split(start_key, 1)[1]
            if content_after_start.strip().startswith(":") or content_after_start.strip().startswith("ï¼š"):
                content_after_start = content_after_start.strip()[1:]
            target_content = ""
            if end_key in content_after_start:
                target_content = content_after_start.split(end_key, 1)[0]
            else:
                found_backup = False
                for k in backup_end_keys:
                    if k in content_after_start:
                        target_content = content_after_start.split(k, 1)[0]
                        found_backup = True
                        break
                if not found_backup:
                    target_content = content_after_start[:100]
            return target_content.strip()
        except: return ""

    def process_detail_page_in_new_tab(self, search_num):
        try:
            WebDriverWait(self.driver, 15).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
            time.sleep(0.5) 
            full_text = self.get_full_text_safe()
            
            license_no = ""
            regex_pattern = fr"(\(\s*{self.target_year}\s*\).*?è™Ÿ)"
            match = re.search(regex_pattern, full_text)
            if match: license_no = match.group(1)
            else:
                match = re.search(r"(æ¡ƒå¸‚.*?åŸ·ç…§.*?è™Ÿ)", full_text)
                license_no = match.group(1) if match else ""

            if not license_no and ("åŸ·ç…§" not in full_text): return
            if not license_no: license_no = f"[éœ€äººå·¥ç¢ºèª] {search_num}"

            builder = self.extract_value_from_text(full_text, ["å§“å"], ["äº‹å‹™æ‰€", "é›»è©±"]) 
            if not builder: builder = self.extract_value_from_text(full_text, ["èµ·é€ äºº"], ["è¨­è¨ˆäºº"])

            raw_location = self.extract_value_from_text(full_text, ["åœ°å€", "å»ºç¯‰åœ°é»", "åœ°è™Ÿ", "åŸºåœ°åè½"], ["ä½¿ç”¨åˆ†å€", "åŸºåœ°é¢ç©"])
            district = ""
            clean_location = raw_location
            if "å€" in raw_location:
                try:
                    idx = raw_location.find("å€")
                    start = max(0, idx - 3)
                    candidate = raw_location[start:idx+1]
                    if "å¸‚" in candidate: district = candidate.split("å¸‚")[-1]
                    else: district = candidate[-3:]
                    clean_location = raw_location.strip()
                except: pass

            zoning = self.extract_value_from_text(full_text, ["ä½¿ç”¨åˆ†å€"], ["åŸºåœ°é¢ç©", "å»ºç‰©æ¦‚è¦"])
            units = self.extract_value_from_text(full_text, ["å±¤æ£Ÿæˆ¶æ•¸"], ["è¨­è¨ˆå»ºè”½ç‡", "æ³•å®šç©ºåœ°"])
            
            site_area_total = self.extract_value_from_text(full_text, ["åˆè¨ˆ", "åŸºåœ°é¢ç©"], ["ã¡", "m2", "é¨æ¨“åœ°"])
            if site_area_total and "ã¡" not in site_area_total: site_area_total += " ã¡"

            build_area_other = ""
            if "å»ºç¯‰é¢ç©" in full_text:
                try:
                    text_after_build = full_text.split("å»ºç¯‰é¢ç©", 1)[1]
                    build_area_other = self.extract_value_from_text(text_after_build, ["å…¶ä»–"], ["ã¡", "m2"])
                    if build_area_other: build_area_other += " ã¡"
                except: pass

            legal_open = self.extract_value_from_text(full_text, ["æ³•å®šç©ºåœ°é¢ç©", "æ³•å®šç©ºåœ°"], ["ã¡", "m2"])
            if legal_open: legal_open += " ã¡"
            floor_area = self.extract_value_from_text(full_text, ["ç¸½æ¨“åœ°æ¿é¢ç©", "æ¨“åœ°æ¿é¢ç©"], ["ã¡", "m2"])
            if floor_area: floor_area += " ã¡"
            date = self.extract_value_from_text(full_text, ["ç™¼ç…§æ—¥æœŸ"], ["æ³¨æ„äº‹é …", "ä¾›å…¬çœ¾"])
            usage_data = self.extract_usage_between_keywords(full_text)

            record = {
                "æœå°‹ç·¨è™Ÿ": search_num,
                "åŸ·ç…§è™Ÿç¢¼": license_no,
                "èµ·é€ äºº": builder,
                "è¡Œæ”¿å€": district,
                "å»ºç¯‰åœ°é»": clean_location,
                "ä½¿ç”¨åˆ†å€": zoning,
                "å±¤æ£Ÿæˆ¶æ•¸": units,
                "åŸºåœ°é¢ç©(åˆè¨ˆ)": site_area_total,
                "å»ºç¯‰é¢ç©(å…¶ä»–)": build_area_other,
                "æ³•å®šç©ºåœ°é¢ç©": legal_open,
                "ç¸½æ¨“åœ°æ¿é¢ç©": floor_area,
                "ç™¼ç…§æ—¥æœŸ": date,
                "ä½¿ç”¨é¡çµ„": usage_data
            }
            
            self.results.append(record)
            self.save_row_to_csv(record)
            logger.info(f"   âœ… [{self.target_year}å¹´] {license_no} | {district} | åœ°é»: {clean_location[:10]}")

        except Exception as e:
            logger.error(f"   âŒ [{self.target_year}å¹´] è§£æå¤±æ•—: {e}")

    def search_and_process_single_try(self, number_val):
        num_str = f"{number_val:05d}"
        try:
            self.driver.get(self.url)
            wait = WebDriverWait(self.driver, 10)
            
            # ğŸ”¥ åš´æ ¼ä½¿ç”¨ .clear()
            year_input = wait.until(EC.visibility_of_element_located((By.XPATH, "//input[contains(@placeholder, 'å¹´åº¦')] | //input[@name='keYear']")))
            year_input.clear()
            year_input.send_keys(self.target_year)
            
            no_input = self.driver.find_element(By.XPATH, "//input[contains(@placeholder, 'è™Ÿç¢¼')] | //input[@name='keNo']")
            no_input.clear()
            no_input.send_keys(num_str)

            code = self.solve_captcha_direct()
            if code:
                self.driver.find_element(By.XPATH, "//input[contains(@placeholder, 'é©—è­‰ç¢¼')] | //input[@name='checkCode']").send_keys(code)
            
            self.driver.find_element(By.XPATH, "//input[@type='button' and @value='æŸ¥è©¢'] | //button[contains(., 'æŸ¥è©¢')]").click()
            
            try:
                WebDriverWait(self.driver, 2).until(EC.alert_is_present())
                self.driver.switch_to.alert.accept()
                return False 
            except TimeoutException: pass

            try: wait.until(EC.presence_of_element_located((By.TAG_NAME, "table")))
            except: return False 

            links = self.driver.find_elements(By.XPATH, "//table//tr/td//a[contains(@href, 'do')]")
            if not links: return False 

            logger.info(f"ğŸ” [{self.target_year}å¹´][{num_str}] æ‰¾åˆ° {len(links)} ç­†")
            self.main_window = self.driver.current_window_handle
            
            for i in range(len(links)):
                links = self.driver.find_elements(By.XPATH, "//table//tr/td//a[contains(@href, 'do')]")
                if i >= len(links): break
                href = links[i].get_attribute('href')
                self.driver.execute_script(f"window.open('{href}', '_blank');")
                time.sleep(2.0)
                new_window = [w for w in self.driver.window_handles if w != self.main_window][0]
                self.driver.switch_to.window(new_window)
                self.process_detail_page_in_new_tab(num_str)
                self.driver.close()
                self.driver.switch_to.window(self.main_window)
                time.sleep(0.5)
            
            return True 

        except Exception as e:
            if "unexpectedly exited" in str(e) or "disconnected" in str(e):
                logger.warning(f"ğŸš¨ Driver å´©æ½°ï¼Œé‡å•Ÿä¸­...")
                self.close_driver()
                time.sleep(3)
                self.init_driver()
            return False

    def run(self):
        self.init_driver()
        logger.info(f"ğŸŸ¢ [{self.target_year}å¹´] ç«åŠ›å…¨é–‹ç‰ˆå•Ÿå‹• | ç¯„åœ: {self.start_num}~{self.end_num}")
        
        consecutive_year_fails = 0 
        counter = 0
        
        for i in range(self.start_num, self.end_num + 1):
            
            if counter > 0 and counter % 50 == 0:
                logger.info(f"â™»ï¸ [{self.target_year}å¹´] æ›æ°£é‡‹æ”¾è¨˜æ†¶é«”...")
                self.close_driver()
                time.sleep(2)
                self.init_driver()

            current_num_found = False
            for retry in range(1, MAX_SAME_NUM_RETRIES + 1):
                if self.search_and_process_single_try(i):
                    current_num_found = True
                    break 
                else:
                    if retry < MAX_SAME_NUM_RETRIES:
                        time.sleep(1.0) 
            
            if current_num_found:
                consecutive_year_fails = 0 
            else:
                consecutive_year_fails += 1
                logger.warning(f"âŒ [{self.target_year}å¹´][{i:05d}] ç©ºè™Ÿ (ç´¯ç© {consecutive_year_fails}/{MAX_CONSECUTIVE_YEAR_FAILS})")

            if consecutive_year_fails >= MAX_CONSECUTIVE_YEAR_FAILS:
                logger.info(f"ğŸ›‘ [{self.target_year}å¹´] é€£çºŒ {MAX_CONSECUTIVE_YEAR_FAILS} ç­†ç©ºè™Ÿï¼Œåˆ¤å®šçµæŸã€‚")
                break 

            counter += 1
            time.sleep(random.uniform(2.0, 3.5)) 
            
        if self.results:
            try:
                output_path = os.path.join(self.target_folder, self.output_filename)
                pd.DataFrame(self.results).to_excel(output_path, index=False)
                logger.info(f"ğŸ’¾ [{self.target_year}å¹´] Excel ç”¢å‡º: {output_path}")
            except: pass
        else:
            logger.info(f"âš ï¸ [{self.target_year}å¹´] ç„¡è³‡æ–™")
            
        self.driver.quit()

def run_scraper_thread(year, start, end):
    filename = f"tycg_permits_{year}_ALL_AT_ONCE_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
    try:
        bot = TyScraperStrict114(year, start, end, filename)
        bot.run()
    except Exception as e:
        logger.error(f"âŒ ç·šç¨‹ [{year}å¹´] éŒ¯èª¤: {e}")

if __name__ == "__main__":
    print(f"ğŸš€ å•Ÿå‹• [114~110å¹´] äº”è¦–çª—ç«åŠ›å…¨é–‹ç‰ˆ")
    print(f"âœ¨ åŸ·è¡Œæ¨¡å¼: 5 å¹´ä»½åŒæ™‚åŸ·è¡Œ (è«‹ç¢ºä¿é›»æºå·²æ¥ä¸Š)")
    print(f"âœ¨ ä½¿ç”¨ .clear() åš´æ ¼æœå°‹ | CSV å³æ™‚å­˜æª”")

    for batch in YEAR_BATCHES:
        print(f"\n======== ğŸ¬ é–‹å§‹åŸ·è¡Œæ‰¹æ¬¡ï¼š{batch} ========")
        threads = []
        for year in batch:
            t = threading.Thread(target=run_scraper_thread, args=(year, START_NUM, END_NUM))
            threads.append(t)
            t.start()
            time.sleep(5) 

        for t in threads:
            t.join()
        
        print(f"âœ… ä»»å‹™å®Œæˆï¼")

    print("\nğŸ 114~110 å…¨æ•¸ä»»å‹™å®Œæˆï¼")
